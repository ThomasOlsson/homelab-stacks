version: "3.9"
networks:
  proxy:
    external: true
  ai: {}

services:
  litellm:
    container_name: litellm
    image: ghcr.io/berriai/litellm:latest
    command: ["--port","4000","--config","/app/config.yaml"]
    dns:
      - 10.2.1.130
    volumes:
      - /srv/docker/litellm/config:/app:ro
    networks: [proxy, ai]
    restart: unless-stopped
    labels:
      traefik.enable: "true"
      traefik.http.routers.litellm.rule: Host(`openai.homehub.dk`)
      traefik.http.routers.litellm.entrypoints: websecure
      traefik.http.services.litellm.loadbalancer.server.port: "4000"
      traefik.http.routers.litellm.middlewares: authentik@docker

  open-webui:
    container_name: open-webui
    image: ghcr.io/open-webui/open-webui:main
    environment:
      OLLAMA_BASE_URLS: "http://ollama.homehub.dk:11434"
      QDRANT_URI: "http://qdrant.homehub.dk:6333"
      QDRANT_API_KEY: "${QDRANT_API_KEY}"
      WEBUI_SECRET_KEY: "${WEBUI_SECRET_KEY}"
    dns:
      - 10.2.1.130
    volumes:
      - /srv/docker/open-webui/data:/app/backend/data
    networks: [proxy, ai]
    restart: unless-stopped
    labels:
      traefik.enable: "true"
      traefik.http.routers.webui.rule: Host(`chat.homehub.dk`)
      traefik.http.routers.webui.entrypoints: websecure
      traefik.http.services.webui.loadbalancer.server.port: "8080"
      traefik.http.routers.webui.middlewares: authentik@docker

